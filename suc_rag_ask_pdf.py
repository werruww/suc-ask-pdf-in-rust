# -*- coding: utf-8 -*-
"""suc_rag_ask_pdf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16gdVFUWb6iKPK_guYjLKdVRyzRvGYzX9
"""







"""### https://github.com/yarenty/kowalski

A Rust-based agent for interacting with Ollama models
"""





!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y

import os
os.environ['PATH'] += ":$HOME/.cargo/bin"

# ØªØ«Ø¨ÙŠØª Rust
!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y

# ØªØ­Ø¯ÙŠØ« Ù…ØªØºÙŠØ± PATH Ù„Ø¬Ø¹Ù„Ù‡ Ù…ØªØ§Ø­Ù‹Ø§ Ù„Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù„Ø§Ø­Ù‚Ø©
import os
home_dir = os.path.expanduser("~") # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù€ $HOME
cargo_bin_path = os.path.join(home_dir, ".cargo", "bin")
if cargo_bin_path not in os.environ['PATH']:
    os.environ['PATH'] = f"{cargo_bin_path}:{os.environ['PATH']}"

print("PATH updated.")
!echo $PATH # Ù„Ù„ØªØ­Ù‚Ù‚

!which cargo

!cargo --version

!rustc --version
!cargo --version







# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/yarenty/kowalski.git
# %cd kowalski

!cargo build --release

!cargo fix --bin "kowalski"

!cargo run --release

curl -fsSL https://ollama.com/install.sh | sh
nohup ollama serve &
ollama pull llama3:8b
ollama list

!curl -fsSL https://ollama.com/install.sh | sh

!nohup ollama serve &

!ollama run llama2

Ø¹Ø¯Ù„ Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØªØ§Ø¨
/content/kowalski/src/main.rs
Ø¹Ø¯Ù„ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒÙ…Ø§ Ù‡Ùˆ Ù Ø§ÙˆÙ„Ø§Ù…Ø§

!nohup ollama serve &
!ollama list

!nohup ollama serve &
!cargo run --release

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

/// Main: The entry point of our AI-powered circus.
/// "Main functions are like orchestras - they make everything work together, but nobody notices until something goes wrong."
///
/// This is where the magic happens, or at least where we pretend it does.
/// Think of it as the conductor of our AI symphony, but with more error handling.
mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader; // Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ù„ÙƒÙ† Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ Ù…Ø¹ AcademicAgent
use env_logger;
use log::info;

/// Reads input from a file, because apparently typing is too mainstream.
/// "File reading is like opening presents - you never know what you're gonna get."
///
/// # Arguments
/// * `file_path` - The path to the file (which is probably too long and boring)
///
/// # Returns
/// * `Result<String, Box<dyn std::error::Error>>` - Either the file contents or an error that will make you question your career choices
#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

/// The main function that makes everything work (or at least tries to).
/// "Main functions are like first dates - they're exciting but usually end in disappointment."
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    env_logger::init();

    // Load configuration
    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    // Initialize model manager
    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    // let model_name = "michaelneale/deepseek-r1-goose";
    let model_name = "llama2:latest"; // quickest model

    // List available models
    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    // Check if default model exists and pull it if needed
    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }


    //  TODO: this is just temporary testing code
    //  TODO: remove this once we have a proper CLI interface
    //  TODO: and create examples of how to use the agents instead!
    // Initialize agents
    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?; // config ØªÙ… Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙ‡ Ù‡Ù†Ø§ØŒ Ù„Ø°Ø§ Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ config.clone() Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ academic_agent Ù„Ø§Ø­Ù‚Ù‹Ø§

    // Example: Process a research paper (ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„Ø¥Ø±Ø³Ø§Ù„ Ø³Ø¤Ø§Ù„ Ù†ØµÙŠ)
    println!("\nSending simple question to Academic Agent...");
    let conversation_id_academic = academic_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¶Ø§Ø±Ø¨
    println!("Academic Agent Conversation ID: {}", conversation_id_academic);

    let role_academic = Role::translator(Some(Audience::Scientist), Some(Preset::Questions)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±

    // --- Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---
    let mut response_academic = academic_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        .chat_with_history(
            &conversation_id_academic,
            "What is game theory in one sentence?", // <--- Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ· ÙƒÙ†Øµ
            Some(role_academic),
        )
        .await?;
    // --- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---

    let mut buffer_academic = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    while let Some(chunk) = response_academic.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        match academic_agent.process_stream_response(&conversation_id_academic, &chunk).await {
            Ok(Some(content)) => {
                print!("{}", content);
                io::stdout().flush()?;
                buffer_academic.push_str(&content);
            }
            Ok(None) => {
                academic_agent.add_message(&conversation_id_academic, "assistant", &buffer_academic).await;
                println!("\n");
                break;
            }
            Err(e) => {
                eprintln!("\nError processing stream: {}", e);
                break;
            }
        }
    }

    // Example: Web search and processing
    info!("Performing web search...");
    let conversation_id_tooling = tooling_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    info!("Tooling Agent Conversation ID: {}", conversation_id_tooling);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent.add_message(&conversation_id_tooling, "search", format!("{} : {}", result.title, result.snippet).as_str()).await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}", result.snippet);
        println!();
    }

    tooling_agent.add_message(&conversation_id_tooling, "user", format!("Search for {} and summary", query).as_str()).await;


    // Process the first search result
    if let Some(first_result) = search_results.first() {
        info!("\nProcessing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;

        tooling_agent.add_message(&conversation_id_tooling, "search", format!(" Full page:{} : {}", page.title, page.content).as_str()).await;

        let role_tooling = Role::translator(Some(Audience::Family), Some(Preset::Simplify)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        let mut response_tooling = tooling_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            .chat_with_history(&conversation_id_tooling, "Provide simple summary", Some(role_tooling))
            .await?;

        let mut buffer_tooling = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        while let Some(chunk) = response_tooling.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            match tooling_agent.process_stream_response(&conversation_id_tooling, &chunk).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer_tooling.push_str(&content);
                }
                Ok(None) => {
                    tooling_agent.add_message(&conversation_id_tooling, "assistant", &buffer_tooling).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nError processing stream: {}", e);
                    break;
                }
            }
        }
    }

    Ok(())
}



!nohup ollama serve &
!ollama run mistral

[ollama]
base_url = "http://localhost:11434"
default_model = "mistral-small"

[chat]
temperature = 0.7
max_tokens = 512
stream = true

https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q2_K.gguf

"""Ø§Ù„Ø§Ù…Ø±

ØªØ­Ø³ÙŠÙ† ØªØ¬Ù…ÙŠØ¹ Ø´ÙŠÙØ±Ø© Rust Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ ØªØ¬Ù…ÙŠØ¹ Ø´ÙŠÙØ±Ø© RustØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©ØŒ Ù…Ø«Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… cargo build --release Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„. Ø¥Ù„ÙŠÙƒ Ø´Ø±Ø­Ù‹Ø§ Ù„ÙƒÙŠÙÙŠØ© Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø°Ù„Ùƒ:

1. Ø§Ø³ØªØ®Ø¯Ø§Ù… cargo build --release

Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ cargo build --releaseØŒ ÙŠÙ‚ÙˆÙ… Rust Ø¨ØªØ¬Ù…ÙŠØ¹ Ø´ÙŠÙØ±ØªÙƒ Ù…Ø¹ ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª. Ù‡Ø°Ù‡ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª ØªØ¬Ø¹Ù„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙØ¬Ù…Ù‘Ø¹ Ø£Ø³Ø±Ø¹ØŒ Ù„ÙƒÙ†Ù‡Ø§ ØªØ³ØªØºØ±Ù‚ ÙˆÙ‚ØªÙ‹Ø§ Ø£Ø·ÙˆÙ„ Ù„Ù„ØªØ¬Ù…ÙŠØ¹.

Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ø¹Ù†Ø¯ Ø¥Ù†Ø´Ø§Ø¡ Ø¥ØµØ¯Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ù† ØªØ·Ø¨ÙŠÙ‚ÙƒØŒ Ø­ÙŠØ« Ø³ÙŠØªÙ… ØªÙ†ÙÙŠØ°Ù‡ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ø¯ÙˆÙ† Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹.

cargo build --release
Use code with caution
2. ØªÙ‚Ù†ÙŠØ§Øª Ø£Ø®Ø±Ù‰ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡:

Ø§Ø³ØªØ®Ø¯Ø§Ù… LTO (Link-Time Optimization): ØªÙ…ÙƒÙŠÙ† LTO Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯ Ø¹Ø¨Ø± ÙˆØ­Ø¯Ø§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©.
Ø£Ø¶Ù lto = true Ø¥Ù„Ù‰ Ù‚Ø³Ù… [profile.release] ÙÙŠ Ù…Ù„Ù Cargo.toml Ø§Ù„Ø®Ø§Øµ Ø¨Ù…Ø´Ø±ÙˆØ¹Ùƒ.
ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬:
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¹Ù„Ø§Ù…Ø© -C target-cpu=native Ù„ØªÙØ¹ÙŠÙ„ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø®Ø§ØµØ© Ø¨Ù…Ø¹Ø§Ù„Ø¬Ùƒ.
ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ®ØµÙŠØµØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©:
ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Box, Rc, Ùˆ Arc Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ø°Ù„Ùƒ Ù…Ù…ÙƒÙ†Ù‹Ø§ Ù„ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø©.
Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ù†ÙˆØ§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ÙØ¹Ù‘Ø§Ù„Ø©:
Ø§Ø®ØªØ± Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙŠ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø¬Ø§ØªÙƒ. Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ø§Ø³ØªØ®Ø¯Ù… u8 Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† i32 Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ù„Ù… Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ù„Ù† ØªÙƒÙˆÙ† Ø³Ø§Ù„Ø¨Ø©.
Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø§Øª Ù…ÙØ­Ø³Ù‘Ù†Ø©:
ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¥ØµØ¯Ø§Ø±Ø§Øª Ù…ÙØ­Ø³Ù‘Ù†Ø© Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªÙŠ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§.
Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù‡Ø§Ù…Ø©:

Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ù‚Ø¯ ØªØ®ØªÙ„Ù: ØªØ¹ØªÙ…Ø¯ ÙØ¹Ø§Ù„ÙŠØ© Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¹Ù„Ù‰ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ ØªÙ‚ÙˆÙ… Ø¨ØªØ¬Ù…ÙŠØ¹Ù‡.
Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù„Ø§Ø²Ù… Ù„Ù„ØªØ¬Ù…ÙŠØ¹: Ù‚Ø¯ ØªØ³ØªØºØ±Ù‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆÙ‚ØªÙ‹Ø§ Ø£Ø·ÙˆÙ„ØŒ Ù„ÙƒÙ†Ù‡Ø§ ØªØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù….
Ø§Ù„ØªØ¬Ø±Ø¨Ø©: Ø¬Ø±Ø¨ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø§ ÙŠÙ†Ø§Ø³Ø¨ Ù…Ø´Ø±ÙˆØ¹Ùƒ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„.
Ø£ØªÙ…Ù†Ù‰ Ø£Ù† ÙŠÙƒÙˆÙ† Ù‡Ø°Ø§ Ø§Ù„Ø´Ø±Ø­ Ù…ÙÙŠØ¯Ù‹Ø§!

### @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@Ø´ØºØ§Ù„
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

Ø´ØºØ§Ù„
/content/kowalski/src/main.rsØµ


/// Main: The entry point of our AI-powered circus.
/// "Main functions are like orchestras - they make everything work together, but nobody notices until something goes wrong."
///
/// This is where the magic happens, or at least where we pretend it does.
/// Think of it as the conductor of our AI symphony, but with more error handling.
mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader; // Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ù„ÙƒÙ† Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ Ù…Ø¹ AcademicAgent
use env_logger;
use log::info;

/// Reads input from a file, because apparently typing is too mainstream.
/// "File reading is like opening presents - you never know what you're gonna get."
///
/// # Arguments
/// * `file_path` - The path to the file (which is probably too long and boring)
///
/// # Returns
/// * `Result<String, Box<dyn std::error::Error>>` - Either the file contents or an error that will make you question your career choices
#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

/// The main function that makes everything work (or at least tries to).
/// "Main functions are like first dates - they're exciting but usually end in disappointment."
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    env_logger::init();

    // Load configuration
    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    // Initialize model manager
    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    // let model_name = "michaelneale/deepseek-r1-goose";
    let model_name = "llama2:latest"; // quickest model

    // List available models
    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    // Check if default model exists and pull it if needed
    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }


    //  TODO: this is just temporary testing code
    //  TODO: remove this once we have a proper CLI interface
    //  TODO: and create examples of how to use the agents instead!
    // Initialize agents
    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?; // config ØªÙ… Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙ‡ Ù‡Ù†Ø§ØŒ Ù„Ø°Ø§ Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ config.clone() Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ academic_agent Ù„Ø§Ø­Ù‚Ù‹Ø§

    // Example: Process a research paper (ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„Ø¥Ø±Ø³Ø§Ù„ Ø³Ø¤Ø§Ù„ Ù†ØµÙŠ)
    println!("\nSending simple question to Academic Agent...");
    let conversation_id_academic = academic_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¶Ø§Ø±Ø¨
    println!("Academic Agent Conversation ID: {}", conversation_id_academic);

    let role_academic = Role::translator(Some(Audience::Scientist), Some(Preset::Questions)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±

    // --- Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---
    let mut response_academic = academic_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        .chat_with_history(
            &conversation_id_academic,
            "What is game theory in one sentence?", // <--- Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ· ÙƒÙ†Øµ
            Some(role_academic),
        )
        .await?;
    // --- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---

    let mut buffer_academic = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    while let Some(chunk) = response_academic.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        match academic_agent.process_stream_response(&conversation_id_academic, &chunk).await {
            Ok(Some(content)) => {
                print!("{}", content);
                io::stdout().flush()?;
                buffer_academic.push_str(&content);
            }
            Ok(None) => {
                academic_agent.add_message(&conversation_id_academic, "assistant", &buffer_academic).await;
                println!("\n");
                break;
            }
            Err(e) => {
                eprintln!("\nError processing stream: {}", e);
                break;
            }
        }
    }

    // Example: Web search and processing
    info!("Performing web search...");
    let conversation_id_tooling = tooling_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    info!("Tooling Agent Conversation ID: {}", conversation_id_tooling);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent.add_message(&conversation_id_tooling, "search", format!("{} : {}", result.title, result.snippet).as_str()).await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}", result.snippet);
        println!();
    }

    tooling_agent.add_message(&conversation_id_tooling, "user", format!("Search for {} and summary", query).as_str()).await;


    // Process the first search result
    if let Some(first_result) = search_results.first() {
        info!("\nProcessing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;

        tooling_agent.add_message(&conversation_id_tooling, "search", format!(" Full page:{} : {}", page.title, page.content).as_str()).await;

        let role_tooling = Role::translator(Some(Audience::Family), Some(Preset::Simplify)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        let mut response_tooling = tooling_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            .chat_with_history(&conversation_id_tooling, "Provide simple summary", Some(role_tooling))
            .await?;

        let mut buffer_tooling = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        while let Some(chunk) = response_tooling.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            match tooling_agent.process_stream_response(&conversation_id_tooling, &chunk).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer_tooling.push_str(&content);
                }
                Ok(None) => {
                    tooling_agent.add_message(&conversation_id_tooling, "assistant", &buffer_tooling).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nError processing stream: {}", e);
                    break;
                }
            }
        }
    }

    Ok(())
}

"""@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

ayhgØ´ØºØ§Ù„
"""

/// Main: The entry point of our AI-powered circus.
/// "Main functions are like orchestras - they make everything work together, but nobody notices until something goes wrong."
///
/// This is where the magic happens, or at least where we pretend it does.
/// Think of it as the conductor of our AI symphony, but with more error handling.
mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader; // Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ Ù„ÙƒÙ† Ù„Ù† Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ Ù…Ø¹ AcademicAgent
use env_logger;
use log::info;

/// Reads input from a file, because apparently typing is too mainstream.
/// "File reading is like opening presents - you never know what you're gonna get."
///
/// # Arguments
/// * `file_path` - The path to the file (which is probably too long and boring)
///
/// # Returns
/// * `Result<String, Box<dyn std::error::Error>>` - Either the file contents or an error that will make you question your career choices
#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

/// The main function that makes everything work (or at least tries to).
/// "Main functions are like first dates - they're exciting but usually end in disappointment."
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    env_logger::init();

    // Load configuration
    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    // Initialize model manager
    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    // let model_name = "michaelneale/deepseek-r1-goose";
    let model_name = "llama2:latest"; // quickest model

    // List available models
    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    // Check if default model exists and pull it if needed
    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }


    //  TODO: this is just temporary testing code
    //  TODO: remove this once we have a proper CLI interface
    //  TODO: and create examples of how to use the agents instead!
    // Initialize agents
    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?; // config ØªÙ… Ø§Ø³ØªÙ‡Ù„Ø§ÙƒÙ‡ Ù‡Ù†Ø§ØŒ Ù„Ø°Ø§ Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ config.clone() Ø¥Ø°Ø§ Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ academic_agent Ù„Ø§Ø­Ù‚Ù‹Ø§

    // Example: Process a research paper (ØªÙ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„Ø¥Ø±Ø³Ø§Ù„ Ø³Ø¤Ø§Ù„ Ù†ØµÙŠ)
    println!("\nSending simple question to Academic Agent...");
    let conversation_id_academic = academic_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¶Ø§Ø±Ø¨
    println!("Academic Agent Conversation ID: {}", conversation_id_academic);

    let role_academic = Role::translator(Some(Audience::Scientist), Some(Preset::Questions)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±

    // --- Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---
    let mut response_academic = academic_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        .chat_with_history(
            &conversation_id_academic,
            "What is game theory in one sentence?", // <--- Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ· ÙƒÙ†Øµ
            Some(role_academic),
        )
        .await?;
    // --- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---

    let mut buffer_academic = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    while let Some(chunk) = response_academic.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        match academic_agent.process_stream_response(&conversation_id_academic, &chunk).await {
            Ok(Some(content)) => {
                print!("{}", content);
                io::stdout().flush()?;
                buffer_academic.push_str(&content);
            }
            Ok(None) => {
                academic_agent.add_message(&conversation_id_academic, "assistant", &buffer_academic).await;
                println!("\n");
                break;
            }
            Err(e) => {
                eprintln!("\nError processing stream: {}", e);
                break;
            }
        }
    }

    // Example: Web search and processing
    info!("Performing web search...");
    let conversation_id_tooling = tooling_agent.start_conversation(&model_name); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
    info!("Tooling Agent Conversation ID: {}", conversation_id_tooling);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent.add_message(&conversation_id_tooling, "search", format!("{} : {}", result.title, result.snippet).as_str()).await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}", result.snippet);
        println!();
    }

    tooling_agent.add_message(&conversation_id_tooling, "user", format!("Search for {} and summary", query).as_str()).await;


    // Process the first search result
    if let Some(first_result) = search_results.first() {
        info!("\nProcessing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;

        tooling_agent.add_message(&conversation_id_tooling, "search", format!(" Full page:{} : {}", page.title, page.content).as_str()).await;

        let role_tooling = Role::translator(Some(Audience::Family), Some(Preset::Simplify)); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        let mut response_tooling = tooling_agent // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            .chat_with_history(&conversation_id_tooling, "Provide simple summary", Some(role_tooling))
            .await?;

        let mut buffer_tooling = String::new(); // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
        while let Some(chunk) = response_tooling.chunk().await? { // ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ØªØºÙŠØ±
            match tooling_agent.process_stream_response(&conversation_id_tooling, &chunk).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer_tooling.push_str(&content);
                }
                Ok(None) => {
                    tooling_agent.add_message(&conversation_id_tooling, "assistant", &buffer_tooling).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nError processing stream: {}", e);
                    break;
                }
            }
        }
    }

    Ok(())
}











mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader;
use env_logger;
use log::info;
use tokio::time::{timeout, Duration};

#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();
    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    let model_name = "llama2:latest"; // Ù†Ù…ÙˆØ°Ø¬ Ø³Ø±ÙŠØ¹ ÙˆØ®ÙÙŠÙ

    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }

    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?;

    println!("\nğŸ“„ Processing research paper...");
    let conversation_id = academic_agent.start_conversation(&model_name);
    println!("Academic Agent Conversation ID: {}", conversation_id);

    let role = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
    let mut response = academic_agent
        .chat_with_history(&conversation_id, "/content/game-theory.pdf", Some(role))
        .await?;

    let mut buffer = String::new();
    let mut total_chars = 0;

    println!("ğŸ§  Thinking...");
    while let Ok(Ok(chunk)) = timeout(Duration::from_secs(10), response.chunk()).await {
        match academic_agent.process_stream_response(&conversation_id, &chunk).await {
            Ok(Some(content)) => {
                print!("{}", content);
                io::stdout().flush()?;
                buffer.push_str(&content);
                total_chars += content.len();
                if total_chars > 1000 {
                    println!("\nâœ‚ï¸ Output truncated after 1000 characters.");
                    break;
                }
            }
            Ok(None) => {
                academic_agent.add_message(&conversation_id, "assistant", &buffer).await;
                println!("\n");
                break;
            }
            Err(e) => {
                eprintln!("\nâš ï¸ Error processing stream: {}", e);
                break;
            }
        }
    }

    info!("ğŸŒ Performing web search...");
    let conversation_id = tooling_agent.start_conversation(&model_name);
    info!("Tooling Agent Conversation ID: {}", conversation_id);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent
            .add_message(&conversation_id, "search", format!("{} : {}", result.title, result.snippet).as_str())
            .await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}\n", result.snippet);
    }

    tooling_agent
        .add_message(&conversation_id, "user", format!("Search for {} and summary", query).as_str())
        .await;

    if let Some(first_result) = search_results.first() {
        info!("ğŸ“„ Fetching and summarizing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;
        tooling_agent
            .add_message(&conversation_id, "search", format!(" Full page:{} : {}", page.title, page.content).as_str())
            .await;

        let role = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
        let mut response = tooling_agent
            .chat_with_history(&conversation_id, "Provide simple summary", Some(role))
            .await?;

        let mut buffer = String::new();
        let mut total_chars = 0;
        println!("ğŸ’¬ Generating summary...");

        while let Ok(Ok(chunk)) = timeout(Duration::from_secs(10), response.chunk()).await {
            match tooling_agent.process_stream_response(&conversation_id, &chunk).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer.push_str(&content);
                    total_chars += content.len();
                    if total_chars > 1000 {
                        println!("\nâœ‚ï¸ Output truncated after 1000 characters.");
                        break;
                    }
                }
                Ok(None) => {
                    tooling_agent.add_message(&conversation_id, "assistant", &buffer).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nâš ï¸ Error processing stream: {}", e);
                    break;
                }
            }
        }
    }

    Ok(())
}

mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader;
use env_logger;
use log::info;

#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();

    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    let model_name = "llama2:latest";

    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }

    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?;

    println!("\nProcessing research paper...");
    let conversation_id = academic_agent.start_conversation(&model_name);
    println!("Academic Agent Conversation ID: {}", conversation_id);

    let role = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
    let mut response = academic_agent
        .chat_with_history(
            &conversation_id,
            "/content/game-theory.pdf",
            Some(role),
        )
        .await?;

    let mut buffer = String::new();
    while let Some(chunk) = response.chunk().await? {
        if let Some(bytes) = &chunk {
            match academic_agent.process_stream_response(&conversation_id, bytes).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer.push_str(&content);
                }
                Ok(None) => {
                    academic_agent.add_message(&conversation_id, "assistant", &buffer).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nError processing stream: {}", e);
                    break;
                }
            }
        }
    }

    info!("Performing web search...");
    let conversation_id = tooling_agent.start_conversation(&model_name);
    info!("Tooling Agent Conversation ID: {}", conversation_id);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent.add_message(
            &conversation_id,
            "search",
            format!("{} : {}", result.title, result.snippet).as_str(),
        ).await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}", result.snippet);
        println!();
    }

    tooling_agent.add_message(
        &conversation_id,
        "user",
        format!("Search for {} and summary", query).as_str(),
    ).await;

    if let Some(first_result) = search_results.first() {
        info!("\nProcessing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;

        tooling_agent.add_message(
            &conversation_id,
            "search",
            format!(" Full page:{} : {}", page.title, page.content).as_str(),
        ).await;

        let role = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
        let mut response = tooling_agent
            .chat_with_history(&conversation_id, "Provide simple summary", Some(role))
            .await?;

        let mut buffer = String::new();
        while let Some(chunk) = response.chunk().await? {
            if let Some(bytes) = &chunk {
                match tooling_agent.process_stream_response(&conversation_id, bytes).await {
                    Ok(Some(content)) => {
                        print!("{}", content);
                        io::stdout().flush()?;
                        buffer.push_str(&content);
                    }
                    Ok(None) => {
                        tooling_agent.add_message(&conversation_id, "assistant", &buffer).await;
                        println!("\n");
                        break;
                    }
                    Err(e) => {
                        eprintln!("\nError processing stream: {}", e);
                        break;
                    }
                }
            }
        }
    }

    Ok(())
}

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

What is game theory in one sentence?

mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

use agent::{Agent, AcademicAgent, ToolingAgent};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::fs;
use std::io::{self, Write};
use utils::PdfReader;
use env_logger;
use log::info;

#[allow(dead_code)]
fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
    if file_path.to_lowercase().ends_with(".pdf") {
        Ok(PdfReader::read_pdf_file(file_path)?)
    } else {
        Ok(fs::read_to_string(file_path)?)
    }
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    env_logger::init();

    let config = config::Config::load()?;
    info!("Loaded configuration with search provider: {}", config.search.provider);

    let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
    let model_name = "llama2:latest";

    info!("Listing available models...");
    let models = model_manager.list_models().await?;
    for model in models.models {
        println!(
            "Model: {}, Size: {} bytes, Modified: {}",
            model.name, model.size, model.modified_at
        );
    }

    if !model_manager.model_exists(&model_name).await? {
        println!("Pulling model {}...", model_name);
        let mut stream = model_manager.pull_model(&model_name).await?;
        while let Some(chunk) = stream.chunk().await? {
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    print!("Status: {}\r", status);
                    io::stdout().flush()?;
                }
            }
        }
        println!("\nModel pulled successfully!");
    }

    let mut academic_agent = AcademicAgent::new(config.clone())?;
    let mut tooling_agent = ToolingAgent::new(config)?;

    println!("\nProcessing research paper...");
    let conversation_id = academic_agent.start_conversation(&model_name);
    println!("Academic Agent Conversation ID: {}", conversation_id);

    let role = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
    let mut response = academic_agent
        .chat_with_history(
            &conversation_id,
            "/content/game-theory.pdf",
            Some(role),
        )
        .await?;

    let mut buffer = String::new();
    while let Some(chunk) = response.chunk().await? {
        if let Some(bytes) = &chunk {
            match academic_agent.process_stream_response(&conversation_id, bytes).await {
                Ok(Some(content)) => {
                    print!("{}", content);
                    io::stdout().flush()?;
                    buffer.push_str(&content);
                }
                Ok(None) => {
                    academic_agent.add_message(&conversation_id, "assistant", &buffer).await;
                    println!("\n");
                    break;
                }
                Err(e) => {
                    eprintln!("\nError processing stream: {}", e);
                    break;
                }
            }
        }
    }

    info!("Performing web search...");
    let conversation_id = tooling_agent.start_conversation(&model_name);
    info!("Tooling Agent Conversation ID: {}", conversation_id);

    let query = "Latest developments in Rust programming";
    let search_results = tooling_agent.search(query).await?;

    for result in &search_results {
        tooling_agent.add_message(
            &conversation_id,
            "search",
            format!("{} : {}", result.title, result.snippet).as_str(),
        ).await;
        println!("Title: {}", result.title);
        println!("URL: {}", result.url);
        println!("Snippet: {}", result.snippet);
        println!();
    }

    tooling_agent.add_message(
        &conversation_id,
        "user",
        format!("Search for {} and summary", query).as_str(),
    ).await;

    if let Some(first_result) = search_results.first() {
        info!("\nProcessing first search result...");
        let page = tooling_agent.fetch_page(&first_result.url).await?;

        tooling_agent.add_message(
            &conversation_id,
            "search",
            format!(" Full page:{} : {}", page.title, page.content).as_str(),
        ).await;

        let role = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
        let mut response = tooling_agent
            .chat_with_history(&conversation_id, "Provide simple summary", Some(role))
            .await?;

        let mut buffer = String::new();
        while let Some(chunk) = response.chunk().await? {
            if let Some(bytes) = &chunk {
                match tooling_agent.process_stream_response(&conversation_id, bytes).await {
                    Ok(Some(content)) => {
                        print!("{}", content);
                        io::stdout().flush()?;
                        buffer.push_str(&content);
                    }
                    Ok(None) => {
                        tooling_agent.add_message(&conversation_id, "assistant", &buffer).await;
                        println!("\n");
                        break;
                    }
                    Err(e) => {
                        eprintln!("\nError processing stream: {}", e);
                        break;
                    }
                }
            }
        }
    }

    Ok(())
}

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/main.rs
# /// Main: The entry point of our AI-powered circus.
# /// "Main functions are like orchestras - they make everything work together, but nobody notices until something goes wrong."
# ///
# /// This is where the magic happens, or at least where we pretend it does.
# /// Think of it as the conductor of our AI symphony, but with more error handling.
# mod agent;
# mod config;
# mod conversation;
# mod model;
# mod role;
# mod utils;
# mod tools;
# 
# use agent::{Agent, AcademicAgent, ToolingAgent};
# use model::ModelManager;
# use role::{Audience, Preset, Role};
# use serde_json::Value;
# use std::fs;
# use std::io::{self, Write}; // io::Write needed for flush
# use utils::PdfReader;
# use env_logger;
# use log::info;
# 
# /// Reads input from a file, because apparently typing is too mainstream.
# /// "File reading is like opening presents - you never know what you're gonna get."
# ///
# /// # Arguments
# /// * `file_path` - The path to the file (which is probably too long and boring)
# ///
# /// # Returns
# /// * `Result<String, Box<dyn std::error::Error>>` - Either the file contents or an error that will make you question your career choices
# #[allow(dead_code)]
# fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
#     if file_path.to_lowercase().ends_with(".pdf") {
#         Ok(PdfReader::read_pdf_file(file_path)?)
#     } else {
#         Ok(fs::read_to_string(file_path)?)
#     }
# }
# 
# /// The main function that makes everything work (or at least tries to).
# /// "Main functions are like first dates - they're exciting but usually end in disappointment."
# #[tokio::main] // This attribute macro makes the async main function work with Tokio
# async fn main() -> Result<(), Box<dyn std::error::Error>> {
#     // Initialize logging
#     env_logger::init();
# 
#     // Load configuration
#     let config = config::Config::load()?;
#     info!("Loaded configuration with search provider: {}", config.search.provider);
# 
#     // Initialize model manager
#     let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
#     // let model_name = "michaelneale/deepseek-r1-goose"; // Example of another model
#     let model_name = "llama2:latest"; // Using "llama2" (will resolve to llama2:latest by default in Ollama)
# 
#     // List available models
#     info!("Listing available models...");
#     let models = model_manager.list_models().await?;
#     for model in models.models {
#         println!(
#             "Model: {}, Size: {} bytes, Modified: {}",
#             model.name, model.size, model.modified_at
#         );
#     }
# 
#     // Check if default model exists and pull it if needed
#     if !model_manager.model_exists(&model_name).await? {
#         println!("Pulling model {} (this might be {} or {} if not fully qualified)...", model_name, model_name, format!("{}:latest", model_name));
#         let mut stream = model_manager.pull_model(&model_name).await?; // Ollama handles "llama2" as "llama2:latest"
#         while let Some(chunk) = stream.chunk().await? {
#             if let Ok(text) = String::from_utf8(chunk.to_vec()) {
#                 let v: Value = serde_json::from_str(&text)?;
#                 if let Some(status) = v["status"].as_str() {
#                     print!("Status: {}\r", status);
#                     io::stdout().flush()?;
#                 }
#             }
#         }
#         println!("\nModel pulled successfully!");
#     } else {
#         info!("Model {} already exists.", model_name);
#     }
# 
#     // Initialize agents
#     let mut academic_agent = AcademicAgent::new(config.clone())?;
#     let mut tooling_agent = ToolingAgent::new(config)?;
# 
#     // --- Academic Agent Interaction ---
#     println!("\n--- Academic Agent ---");
#     let conversation_id_academic = academic_agent.start_conversation(&model_name);
#     println!("Academic Agent Conversation ID: {}", conversation_id_academic);
# 
#     println!("Do you want to provide a PDF file path or type a question directly?");
#     println!("1. PDF file path");
#     println!("2. Type a question");
#     print!("Enter your choice (1 or 2): ");
#     io::stdout().flush()?;
# 
#     let mut choice = String::new();
#     io::stdin().read_line(&mut choice)?;
#     let choice = choice.trim();
# 
#     let input_content_academic: String; // Renamed to avoid conflict
# 
#     if choice == "1" {
#         print!("Enter the path to your PDF file: ");
#         io::stdout().flush()?;
#         let mut file_path_input = String::new();
#         io::stdin().read_line(&mut file_path_input)?;
#         let file_path = file_path_input.trim();
# 
#         if !file_path.is_empty() {
#             info!("Reading PDF file: {}", file_path);
#             match read_input_file(file_path) {
#                 Ok(pdf_text) => {
#                     print!("Enter your question about the PDF: ");
#                     io::stdout().flush()?;
#                     let mut pdf_question = String::new();
#                     io::stdin().read_line(&mut pdf_question)?;
#                     // For simplicity, sending only a part of PDF and the question.
#                     // Real RAG would be more complex.
#                     input_content_academic = format!(
#                         "Based on the following document content (first 2000 chars):\n---\n{}...\n---\nAnswer this question: {}",
#                         pdf_text.chars().take(2000).collect::<String>(),
#                         pdf_question.trim()
#                     );
#                     info!("Processing PDF content and your question...");
#                 }
#                 Err(e) => {
#                     eprintln!("Error reading PDF file: {}. Using a default question.", e);
#                     input_content_academic = "What is game theory in one sentence?".to_string();
#                 }
#             }
#         } else {
#             println!("No PDF path provided. Using a default question.");
#             input_content_academic = "What is game theory in one sentence?".to_string();
#         }
#     } else if choice == "2" {
#         print!("Enter your question for the Academic Agent: ");
#         io::stdout().flush()?;
#         let mut user_question = String::new();
#         io::stdin().read_line(&mut user_question)?;
#         input_content_academic = user_question.trim().to_string();
#         if input_content_academic.is_empty() {
#             println!("No question entered. Using a default question.");
#             input_content_academic = "What is game theory in one sentence?".to_string();
#         }
#     } else {
#         println!("Invalid choice. Using a default question.");
#         input_content_academic = "What is game theory in one sentence?".to_string();
#     }
# 
#     let role_academic = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
# 
#     let mut response_academic = academic_agent
#         .chat_with_history(
#             &conversation_id_academic,
#             &input_content_academic,
#             Some(role_academic),
#         )
#         .await?;
# 
#     let mut buffer_academic = String::new();
#     println!("\nAcademic Agent Response:");
#     while let Some(chunk) = response_academic.chunk().await? {
#         match academic_agent.process_stream_response(&conversation_id_academic, &chunk).await {
#             Ok(Some(content)) => {
#                 print!("{}", content);
#                 io::stdout().flush()?;
#                 buffer_academic.push_str(&content);
#             }
#             Ok(None) => {
#                 academic_agent.add_message(&conversation_id_academic, "assistant", &buffer_academic).await;
#                 println!("\n--- End of Academic Agent Response ---");
#                 break;
#             }
#             Err(e) => {
#                 eprintln!("\nError processing stream for Academic Agent: {}", e);
#                 break;
#             }
#         }
#     }
# 
#     // --- Tooling Agent Interaction ---
#     info!("\n--- Tooling Agent ---");
#     let conversation_id_tooling = tooling_agent.start_conversation(&model_name);
#     info!("Tooling Agent Conversation ID: {}", conversation_id_tooling);
# 
#     print!("Enter your search query for the Tooling Agent (e.g., Latest developments in Rust programming): ");
#     io::stdout().flush()?;
#     let mut user_search_query = String::new();
#     io::stdin().read_line(&mut user_search_query)?;
#     let query_tooling = user_search_query.trim(); // Renamed to avoid conflict
# 
#     if query_tooling.is_empty() {
#         println!("No search query entered. Skipping web search.");
#     } else {
#         info!("Performing web search for: {}", query_tooling);
#         let search_results = tooling_agent.search(query_tooling).await?;
# 
#         for result in &search_results {
#             tooling_agent.add_message(&conversation_id_tooling, "search", format!("{} : {}", result.title, result.snippet).as_str()).await;
#             println!("Title: {}", result.title);
#             println!("URL: {}", result.url);
#             // println!("Snippet: {}", result.snippet); // Can be verbose
#             println!();
#         }
# 
#         tooling_agent.add_message(&conversation_id_tooling, "user", format!("Search for {} and summarize the first result.", query_tooling).as_str()).await;
# 
#         if let Some(first_result) = search_results.first() {
#             info!("\nProcessing first search result: {}", first_result.url);
#             match tooling_agent.fetch_page(&first_result.url).await {
#                 Ok(page) => {
#                     tooling_agent.add_message(&conversation_id_tooling, "search", format!("Full page content from {}: {}...", page.url, page.content.chars().take(500).collect::<String>()).as_str()).await;
# 
#                     let role_tooling = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
#                     let prompt_summary = "Provide a simple summary of the fetched page content.";
#                     let mut response_tooling = tooling_agent
#                         .chat_with_history(&conversation_id_tooling, prompt_summary, Some(role_tooling))
#                         .await?;
# 
#                     let mut buffer_tooling = String::new();
#                     println!("\nTooling Agent Summary Response:");
#                     while let Some(chunk) = response_tooling.chunk().await? {
#                         match tooling_agent.process_stream_response(&conversation_id_tooling, &chunk).await {
#                             Ok(Some(content)) => {
#                                 print!("{}", content);
#                                 io::stdout().flush()?;
#                                 buffer_tooling.push_str(&content);
#                             }
#                             Ok(None) => {
#                                 tooling_agent.add_message(&conversation_id_tooling, "assistant", &buffer_tooling).await;
#                                 println!("\n--- End of Tooling Agent Summary ---");
#                                 break;
#                             }
#                             Err(e) => {
#                                 eprintln!("\nError processing stream for Tooling Agent: {}", e);
#                                 break;
#                             }
#                         }
#                     }
#                 }
#                 Err(e) => {
#                     eprintln!("Failed to fetch page {}: {}", first_result.url, e);
#                 }
#             }
#         } else {
#             println!("No search results to process.");
#         }
#     }
# 
#     println!("\nApplication finished.");
#     Ok(())
# }

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

"""### Ø´ØºØ§Ù„ Ø¬ÙŠØ¯ ÙˆÙ„ÙƒÙ† ÙŠØºÙŠØ¨%%%%%%%%%%%%%%%%%%%%%"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile src/main.rs
# /// Main: The entry point of our AI-powered circus.
# // ... (Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ)
# mod agent;
# mod config;
# mod conversation;
# mod model;
# mod role;
# mod utils;
# mod tools;
# 
# use agent::{Agent, AcademicAgent, ToolingAgent};
# use model::ModelManager;
# use role::{Audience, Preset, Role};
# use serde_json::Value;
# use std::fs;
# use std::io::{self, Write}; // io::Write needed for flush
# use utils::PdfReader;
# use env_logger;
# use log::info;
# 
# /// Reads input from a file, because apparently typing is too mainstream.
# // ... (Ø¨Ù‚ÙŠØ© Ø§Ù„Ø¯Ø§Ù„Ø© ÙƒÙ…Ø§ Ù‡ÙŠ)
# #[allow(dead_code)]
# fn read_input_file(file_path: &str) -> Result<String, Box<dyn std::error::Error>> {
#     if file_path.to_lowercase().ends_with(".pdf") {
#         Ok(PdfReader::read_pdf_file(file_path)?)
#     } else {
#         Ok(fs::read_to_string(file_path)?)
#     }
# }
# 
# /// The main function that makes everything work (or at least tries to).
# // ... (Ø¨Ù‚ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙƒÙ…Ø§ Ù‡ÙŠ)
# #[tokio::main] // This attribute macro makes the async main function work with Tokio
# async fn main() -> Result<(), Box<dyn std::error::Error>> {
#     // Initialize logging
#     env_logger::init();
# 
#     // Load configuration
#     let config = config::Config::load()?;
#     info!("Loaded configuration with search provider: {}", config.search.provider);
# 
#     // Initialize model manager
#     let model_manager = ModelManager::new(config.ollama.base_url.clone())?;
#     let model_name = "llama2";
# 
#     // List available models
#     info!("Listing available models...");
#     let models = model_manager.list_models().await?;
#     for model in models.models {
#         println!(
#             "Model: {}, Size: {} bytes, Modified: {}",
#             model.name, model.size, model.modified_at
#         );
#     }
# 
#     // Check if default model exists and pull it if needed
#     if !model_manager.model_exists(&model_name).await? {
#         println!("Pulling model {} (this might be {} or {} if not fully qualified)...", model_name, model_name, format!("{}:latest", model_name));
#         let mut stream = model_manager.pull_model(&model_name).await?;
#         while let Some(chunk) = stream.chunk().await? {
#             if let Ok(text) = String::from_utf8(chunk.to_vec()) {
#                 let v: Value = serde_json::from_str(&text)?;
#                 if let Some(status) = v["status"].as_str() {
#                     print!("Status: {}\r", status);
#                     io::stdout().flush()?;
#                 }
#             }
#         }
#         println!("\nModel pulled successfully!");
#     } else {
#         info!("Model {} already exists.", model_name);
#     }
# 
#     // Initialize agents
#     let mut academic_agent = AcademicAgent::new(config.clone())?;
#     let mut tooling_agent = ToolingAgent::new(config)?;
# 
#     // --- Academic Agent Interaction ---
#     println!("\n--- Academic Agent ---");
#     let conversation_id_academic = academic_agent.start_conversation(&model_name);
#     println!("Academic Agent Conversation ID: {}", conversation_id_academic);
# 
#     println!("Do you want to provide a PDF file path or type a question directly?");
#     println!("1. PDF file path");
#     println!("2. Type a question");
#     print!("Enter your choice (1 or 2): ");
#     io::stdout().flush()?;
# 
#     let mut choice = String::new();
#     io::stdin().read_line(&mut choice)?;
#     let choice = choice.trim();
# 
#     // *** Ø§Ù„ØªØµØ­ÙŠØ­ Ù‡Ù†Ø§ ***
#     let mut input_content_academic: String; // Ø¬Ø¹Ù„ Ø§Ù„Ù…ØªØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø§Ù‹ Ù„Ù„ØªØºÙŠÙŠØ±
# 
#     if choice == "1" {
#         print!("Enter the path to your PDF file: ");
#         io::stdout().flush()?;
#         let mut file_path_input = String::new();
#         io::stdin().read_line(&mut file_path_input)?;
#         let file_path = file_path_input.trim();
# 
#         if !file_path.is_empty() {
#             info!("Reading PDF file: {}", file_path);
#             match read_input_file(file_path) {
#                 Ok(pdf_text) => {
#                     print!("Enter your question about the PDF: ");
#                     io::stdout().flush()?;
#                     let mut pdf_question = String::new();
#                     io::stdin().read_line(&mut pdf_question)?;
#                     input_content_academic = format!(
#                         "Based on the following document content (first 2000 chars):\n---\n{}...\n---\nAnswer this question: {}",
#                         pdf_text.chars().take(2000).collect::<String>(),
#                         pdf_question.trim()
#                     );
#                     info!("Processing PDF content and your question...");
#                 }
#                 Err(e) => {
#                     eprintln!("Error reading PDF file: {}. Using a default question.", e);
#                     input_content_academic = "What is game theory in one sentence?".to_string();
#                 }
#             }
#         } else {
#             println!("No PDF path provided. Using a default question.");
#             input_content_academic = "What is game theory in one sentence?".to_string();
#         }
#     } else if choice == "2" {
#         print!("Enter your question for the Academic Agent: ");
#         io::stdout().flush()?;
#         let mut user_question = String::new();
#         io::stdin().read_line(&mut user_question)?;
#         input_content_academic = user_question.trim().to_string(); // Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø£ÙˆÙ„
#         if input_content_academic.is_empty() {
#             println!("No question entered. Using a default question.");
#             input_content_academic = "What is game theory in one sentence?".to_string(); // Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø«Ø§Ù†ÙŠ (Ø§Ù„Ø¢Ù† Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡)
#         }
#     } else {
#         println!("Invalid choice. Using a default question.");
#         input_content_academic = "What is game theory in one sentence?".to_string();
#     }
# 
#     let role_academic = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
# 
#     let mut response_academic = academic_agent
#         .chat_with_history(
#             &conversation_id_academic,
#             &input_content_academic,
#             Some(role_academic),
#         )
#         .await?;
# 
#     let mut buffer_academic = String::new();
#     println!("\nAcademic Agent Response:");
#     while let Some(chunk) = response_academic.chunk().await? {
#         match academic_agent.process_stream_response(&conversation_id_academic, &chunk).await {
#             Ok(Some(content)) => {
#                 print!("{}", content);
#                 io::stdout().flush()?;
#                 buffer_academic.push_str(&content);
#             }
#             Ok(None) => {
#                 academic_agent.add_message(&conversation_id_academic, "assistant", &buffer_academic).await;
#                 println!("\n--- End of Academic Agent Response ---");
#                 break;
#             }
#             Err(e) => {
#                 eprintln!("\nError processing stream for Academic Agent: {}", e);
#                 break;
#             }
#         }
#     }
# 
#     // --- Tooling Agent Interaction ---
#     info!("\n--- Tooling Agent ---");
#     let conversation_id_tooling = tooling_agent.start_conversation(&model_name);
#     info!("Tooling Agent Conversation ID: {}", conversation_id_tooling);
# 
#     print!("Enter your search query for the Tooling Agent (e.g., Latest developments in Rust programming): ");
#     io::stdout().flush()?;
#     let mut user_search_query = String::new();
#     io::stdin().read_line(&mut user_search_query)?;
#     let query_tooling = user_search_query.trim();
# 
#     if query_tooling.is_empty() {
#         println!("No search query entered. Skipping web search.");
#     } else {
#         info!("Performing web search for: {}", query_tooling);
#         let search_results = tooling_agent.search(query_tooling).await?;
# 
#         for result in &search_results {
#             tooling_agent.add_message(&conversation_id_tooling, "search", format!("{} : {}", result.title, result.snippet).as_str()).await;
#             println!("Title: {}", result.title);
#             println!("URL: {}", result.url);
#             println!();
#         }
# 
#         tooling_agent.add_message(&conversation_id_tooling, "user", format!("Search for {} and summarize the first result.", query_tooling).as_str()).await;
# 
#         if let Some(first_result) = search_results.first() {
#             info!("\nProcessing first search result: {}", first_result.url);
#             match tooling_agent.fetch_page(&first_result.url).await {
#                 Ok(page) => {
#                     tooling_agent.add_message(&conversation_id_tooling, "search", format!("Full page content from {}: {}...", page.url, page.content.chars().take(500).collect::<String>()).as_str()).await;
# 
#                     let role_tooling = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
#                     let prompt_summary = "Provide a simple summary of the fetched page content.";
#                     let mut response_tooling = tooling_agent
#                         .chat_with_history(&conversation_id_tooling, prompt_summary, Some(role_tooling))
#                         .await?;
# 
#                     let mut buffer_tooling = String::new();
#                     println!("\nTooling Agent Summary Response:");
#                     while let Some(chunk) = response_tooling.chunk().await? {
#                         match tooling_agent.process_stream_response(&conversation_id_tooling, &chunk).await {
#                             Ok(Some(content)) => {
#                                 print!("{}", content);
#                                 io::stdout().flush()?;
#                                 buffer_tooling.push_str(&content);
#                             }
#                             Ok(None) => {
#                                 tooling_agent.add_message(&conversation_id_tooling, "assistant", &buffer_tooling).await;
#                                 println!("\n--- End of Tooling Agent Summary ---");
#                                 break;
#                             }
#                             Err(e) => {
#                                 eprintln!("\nError processing stream for Tooling Agent: {}", e);
#                                 break;
#                             }
#                         }
#                     }
#                 }
#                 Err(e) => {
#                     eprintln!("Failed to fetch page {}: {}", first_result.url, e);
#                 }
#             }
#         } else {
#             println!("No search results to process.");
#         }
#     }
# 
#     println!("\nApplication finished.");
#     Ok(())
# }

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/kowalski
!nohup ollama serve &
!cargo run --release

"""### %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"""

















"""Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ù…Ø«Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ø·ÙˆÙŠÙ„ Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ù„ÙØ§Øª PDF Ù‡Ùˆ ØªÙ†ÙÙŠØ° Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© RAG (Retrieval Augmented Generation) ÙƒØ§Ù…Ù„Ø©:
Ù‚Ø³Ù‘Ù… PDF Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø©.
Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ ØªØ¶Ù…ÙŠÙ†Ø§Øª (embeddings) Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡.
Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø© ÙÙ‚Ø·.
Ø£Ø±Ø³Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© (Ø³ÙŠØ§Ù‚ Ø£ØµØºØ± Ø¨ÙƒØ«ÙŠØ±) Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ.
Ù…Ø´Ø±ÙˆØ¹
"""









https://github.com/yarenty/kowalski/issues/1

// Example CLI structure
   kowalski chat "What's the meaning of life?"
   kowalski pdf analyze research-paper.pdf
   kowalski model list

!kowalski chat "What's the meaning of life?"

ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø§Ø³Ø§Ø³Ù‰ Ù…Ù† Ø§Ù„Ø±ÙŠØ¨Ùˆ
/// Main: Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
/// ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ³Ø¹Ø©ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
use agent::{AcademicAgent, ToolingAgent};
use config::Config;
use crossterm::{
    event::{self, Event, KeyCode},
    execute,
    terminal::{disable_raw_mode, enable_raw_mode, EnterAlternateScreen, LeaveAlternateScreen},
};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::{
    error::Error,
    fs,
    io::{self, stdout, Write},
    time::Duration,
};
use tui::{backend::CrosstermBackend, widgets::{Widget, Block, Borders}, Terminal};
use utils::PdfReader;

mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

// Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
const TIMEOUT_DURATION: u64 = 30; // Ø«Ø§Ù†ÙŠØ©
const MAX_FILE_SIZE: usize = 10_000_000; // 10MB

/// Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ³Ø¹Ø©
#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("info")).init();

    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø·Ø±ÙÙŠØ©
    let mut stdout = stdout();
    execute!(stdout, EnterAlternateScreen)?;
    enable_raw_mode()?;
    let backend = CrosstermBackend::new(stdout);
    let mut terminal = Terminal::new(backend)?;

    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    let config = Config::load().map_err(|e| format!("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {}", e))?;

    // Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    let model_manager = ModelManager::new(config.ollama.base_url.clone())
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {}", e))?;

    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    let model_name = "llama2";
    handle_model_setup(&model_manager, model_name).await?;

    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡
    let academic_agent = AcademicAgent::new(config.clone())
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ: {}", e))?;
    let tooling_agent = ToolingAgent::new(config)
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£Ø¯ÙˆØ§Øª: {}", e))?;

    // Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    run_interactive_ui(&model_manager, academic_agent, tooling_agent, &mut terminal).await?;

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø·Ø±ÙÙŠØ©
    disable_raw_mode()?;
    execute!(terminal.backend_mut(), LeaveAlternateScreen)?;
    Ok(())
}

/// Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
async fn handle_model_setup(
    model_manager: &ModelManager,
    model_name: &str,
) -> Result<(), Box<dyn Error>> {
    if !model_manager.model_exists(model_name).await? {
        log::info!("Ø¬Ø§Ø±ÙŠ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {}...", model_name);
        let mut stream = model_manager
            .pull_model(model_name)
            .await
            .map_err(|e| format!("ÙØ´Ù„ ÙÙŠ Ø³Ø­Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {}", e))?;

        let start_time = tokio::time::Instant::now();
        while let Some(chunk) = tokio::time::timeout(
            Duration::from_secs(TIMEOUT_DURATION),
            stream.chunk(),
        )
        .await?
        {
            let chunk = chunk?;
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    log::debug!("Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø²ÙŠÙ„: {}", status);
                }
            }
        }

        model_manager.cache_model(model_name).await?;
        log::info!("ØªÙ… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ {} Ø«Ø§Ù†ÙŠØ©", start_time.elapsed().as_secs());
    }
    Ok(())
}

/// Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
async fn run_interactive_ui(
    model_manager: &ModelManager,
    academic_agent: AcademicAgent,
    tooling_agent: ToolingAgent,
    terminal: &mut Terminal<CrosstermBackend<io::Stdout>>,
) -> Result<(), Box<dyn Error>> {
    loop {
        terminal.draw(|f| {
            let size = f.size();
            let block = Block::default()
                .title("Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
                .borders(Borders::ALL);
            f.render_widget(block, size);
        })?;

        if event::poll(Duration::from_millis(100))? {
            if let Event::Key(key) = event::read()? {
                match key.code {
                    KeyCode::Char('q') => break,
                    KeyCode::Char('s') => handle_search(&tooling_agent).await?,
                    KeyCode::Char('r') => handle_research(&academic_agent).await?,
                    _ => {}
                }
            }
        }
    }
    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¨Ø­Ø«
async fn handle_search(tooling_agent: &ToolingAgent) -> Result<(), Box<dyn Error>> {
    let conversation_id = tooling_agent.start_conversation("llama2");
    let query = "Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ·ÙˆØ±Ø§Øª ÙÙŠ Ø¨Ø±Ù…Ø¬Ø© Rust";

    let search_results = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        tooling_agent.search(query),
    )
    .await??;

    if search_results.is_empty() {
        log::warn!("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø«");
        return Ok(());
    }

    for result in &search_results {
        tooling_agent.add_message(&conversation_id, "search", &format!("{}: {}", result.title, result.snippet)).await;
    }

    if let Some(first_result) = search_results.first() {
        let page = tokio::time::timeout(
            Duration::from_secs(TIMEOUT_DURATION),
            tooling_agent.fetch_page(&first_result.url),
        )
        .await??;

        process_content(&page.content, tooling_agent, &conversation_id).await?;
    }

    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨Ø­Ø«ÙŠØ©
async fn handle_research(academic_agent: &AcademicAgent) -> Result<(), Box<dyn Error>> {
    let conversation_id = academic_agent.start_conversation("llama2");
    let file_path = "/opt/research/2025/coddllm_2502.00329v1.pdf";

    let content = read_input_file(file_path)?;
    let role = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));

    let response = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        academic_agent.chat_with_history(&conversation_id, &content, Some(role)),
    )
    .await??;

    process_stream(response, academic_agent, &conversation_id).await?;
    Ok(())
}

/// Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©
fn read_input_file(file_path: &str) -> Result<String, Box<dyn Error>> {
    let metadata = fs::metadata(file_path)?;
    if metadata.len() > MAX_FILE_SIZE as u64 {
        return Err(format!("Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ù‹Ø§: {} Ø¨Ø§ÙŠØª", metadata.len()).into());
    }

    let content = if file_path.to_lowercase().ends_with(".pdf") {
        PdfReader::read_pdf_file(file_path)?
    } else {
        fs::read_to_string(file_path)?
    };

    if content.trim().is_empty() {
        return Err("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø±Øº".into());
    }

    Ok(content)
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙˆÙ‚Øª
async fn process_content(
    content: &str,
    agent: &ToolingAgent,
    conversation_id: &str,
) -> Result<(), Box<dyn Error>> {
    let role = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
    let response = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        agent.chat_with_history(conversation_id, &format!("Ù„Ø®Øµ Ù„ÙŠ Ù‡Ø°Ø§: {}", content), Some(role)),
    )
    .await??;

    process_stream(response, agent, conversation_id).await?;
    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ¯ÙÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
async fn process_stream(
    mut response: impl Stream<Item = Result<Bytes, reqwest::Error>> + Unpin,
    agent: &impl Agent,
    conversation_id: &str,
) -> Result<(), Box<dyn Error>> {
    let mut buffer = String::new();
    while let Some(chunk) = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        response.next(),
    )
    .await?
    {
        let chunk = chunk?;
        let content = agent.process_stream_response(conversation_id, &chunk)
            .await
            .map_err(|e| format!("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {}", e))??;

        if let Some(content) = content {
            print!("{}", content);
            io::stdout().flush()?;
            buffer.push_str(&content);
        }
    }

    agent.add_message(conversation_id, "assistant", &buffer)
        .await
        .map_err(|e| format!("ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {}", e))?;
    Ok(())
}

"""Ø³Ø£Ù‚ÙˆÙ… Ø¨Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯ Ù…Ø¹ Ø¯Ù…Ø¬ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©. Ù„Ø§Ø­Ø¸ Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ¨Ø¹ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ `Cargo.toml`:

```rust
/// Main: Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
/// ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ³Ø¹Ø©ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
use agent::{AcademicAgent, ToolingAgent};
use config::Config;
use crossterm::{
    event::{self, Event, KeyCode},
    execute,
    terminal::{disable_raw_mode, enable_raw_mode, EnterAlternateScreen, LeaveAlternateScreen},
};
use model::ModelManager;
use role::{Audience, Preset, Role};
use serde_json::Value;
use std::{
    error::Error,
    fs,
    io::{self, stdout, Write},
    time::Duration,
};
use tui::{backend::CrosstermBackend, widgets::{Widget, Block, Borders}, Terminal};
use utils::PdfReader;

mod agent;
mod config;
mod conversation;
mod model;
mod role;
mod utils;
mod tools;

// Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
const TIMEOUT_DURATION: u64 = 30; // Ø«Ø§Ù†ÙŠØ©
const MAX_FILE_SIZE: usize = 10_000_000; // 10MB

/// Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ³Ø¹Ø©
#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    env_logger::Builder::from_env(env_logger::Env::default().default_filter_or("info")).init();

    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø·Ø±ÙÙŠØ©
    let mut stdout = stdout();
    execute!(stdout, EnterAlternateScreen)?;
    enable_raw_mode()?;
    let backend = CrosstermBackend::new(stdout);
    let mut terminal = Terminal::new(backend)?;

    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    let config = Config::load().map_err(|e| format!("ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {}", e))?;

    // Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    let model_manager = ModelManager::new(config.ollama.base_url.clone())
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {}", e))?;
    
    // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    let model_name = "llama2";
    handle_model_setup(&model_manager, model_name).await?;

    // ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡
    let academic_agent = AcademicAgent::new(config.clone())
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ: {}", e))?;
    let tooling_agent = ToolingAgent::new(config)
        .map_err(|e| format!("ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£Ø¯ÙˆØ§Øª: {}", e))?;

    // Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    run_interactive_ui(&model_manager, academic_agent, tooling_agent, &mut terminal).await?;

    // ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø·Ø±ÙÙŠØ©
    disable_raw_mode()?;
    execute!(terminal.backend_mut(), LeaveAlternateScreen)?;
    Ok(())
}

/// Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
async fn handle_model_setup(
    model_manager: &ModelManager,
    model_name: &str,
) -> Result<(), Box<dyn Error>> {
    if !model_manager.model_exists(model_name).await? {
        log::info!("Ø¬Ø§Ø±ÙŠ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {}...", model_name);
        let mut stream = model_manager
            .pull_model(model_name)
            .await
            .map_err(|e| format!("ÙØ´Ù„ ÙÙŠ Ø³Ø­Ø¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {}", e))?;

        let start_time = tokio::time::Instant::now();
        while let Some(chunk) = tokio::time::timeout(
            Duration::from_secs(TIMEOUT_DURATION),
            stream.chunk(),
        )
        .await?
        {
            let chunk = chunk?;
            if let Ok(text) = String::from_utf8(chunk.to_vec()) {
                let v: Value = serde_json::from_str(&text)?;
                if let Some(status) = v["status"].as_str() {
                    log::debug!("Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø²ÙŠÙ„: {}", status);
                }
            }
        }
        
        model_manager.cache_model(model_name).await?;
        log::info!("ØªÙ… Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ {} Ø«Ø§Ù†ÙŠØ©", start_time.elapsed().as_secs());
    }
    Ok(())
}

/// Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
async fn run_interactive_ui(
    model_manager: &ModelManager,
    academic_agent: AcademicAgent,
    tooling_agent: ToolingAgent,
    terminal: &mut Terminal<CrosstermBackend<io::Stdout>>,
) -> Result<(), Box<dyn Error>> {
    loop {
        terminal.draw(|f| {
            let size = f.size();
            let block = Block::default()
                .title("Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
                .borders(Borders::ALL);
            f.render_widget(block, size);
        })?;

        if event::poll(Duration::from_millis(100))? {
            if let Event::Key(key) = event::read()? {
                match key.code {
                    KeyCode::Char('q') => break,
                    KeyCode::Char('s') => handle_search(&tooling_agent).await?,
                    KeyCode::Char('r') => handle_research(&academic_agent).await?,
                    _ => {}
                }
            }
        }
    }
    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¨Ø­Ø«
async fn handle_search(tooling_agent: &ToolingAgent) -> Result<(), Box<dyn Error>> {
    let conversation_id = tooling_agent.start_conversation("llama2");
    let query = "Ø£Ø­Ø¯Ø« Ø§Ù„ØªØ·ÙˆØ±Ø§Øª ÙÙŠ Ø¨Ø±Ù…Ø¬Ø© Rust";
    
    let search_results = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        tooling_agent.search(query),
    )
    .await??;

    if search_results.is_empty() {
        log::warn!("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø«");
        return Ok(());
    }

    for result in &search_results {
        tooling_agent.add_message(&conversation_id, "search", &format!("{}: {}", result.title, result.snippet)).await;
    }

    if let Some(first_result) = search_results.first() {
        let page = tokio::time::timeout(
            Duration::from_secs(TIMEOUT_DURATION),
            tooling_agent.fetch_page(&first_result.url),
        )
        .await??;

        process_content(&page.content, tooling_agent, &conversation_id).await?;
    }
    
    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨Ø­Ø«ÙŠØ©
async fn handle_research(academic_agent: &AcademicAgent) -> Result<(), Box<dyn Error>> {
    let conversation_id = academic_agent.start_conversation("llama2");
    let file_path = "/opt/research/2025/coddllm_2502.00329v1.pdf";
    
    let content = read_input_file(file_path)?;
    let role = Role::translator(Some(Audience::Scientist), Some(Preset::Questions));
    
    let response = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        academic_agent.chat_with_history(&conversation_id, &content, Some(role)),
    )
    .await??;

    process_stream(response, academic_agent, &conversation_id).await?;
    Ok(())
}

/// Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø©
fn read_input_file(file_path: &str) -> Result<String, Box<dyn Error>> {
    let metadata = fs::metadata(file_path)?;
    if metadata.len() > MAX_FILE_SIZE as u64 {
        return Err(format!("Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ± Ø¬Ø¯Ù‹Ø§: {} Ø¨Ø§ÙŠØª", metadata.len()).into());
    }

    let content = if file_path.to_lowercase().ends_with(".pdf") {
        PdfReader::read_pdf_file(file_path)?
    } else {
        fs::read_to_string(file_path)?
    };

    if content.trim().is_empty() {
        return Err("Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙØ§Ø±Øº".into());
    }

    Ok(content)
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙˆÙ‚Øª
async fn process_content(
    content: &str,
    agent: &ToolingAgent,
    conversation_id: &str,
) -> Result<(), Box<dyn Error>> {
    let role = Role::translator(Some(Audience::Family), Some(Preset::Simplify));
    let response = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        agent.chat_with_history(conversation_id, &format!("Ù„Ø®Øµ Ù„ÙŠ Ù‡Ø°Ø§: {}", content), Some(role)),
    )
    .await??;

    process_stream(response, agent, conversation_id).await?;
    Ok(())
}

/// Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ¯ÙÙ‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
async fn process_stream(
    mut response: impl Stream<Item = Result<Bytes, reqwest::Error>> + Unpin,
    agent: &impl Agent,
    conversation_id: &str,
) -> Result<(), Box<dyn Error>> {
    let mut buffer = String::new();
    while let Some(chunk) = tokio::time::timeout(
        Duration::from_secs(TIMEOUT_DURATION),
        response.next(),
    )
    .await?
    {
        let chunk = chunk?;
        let content = agent.process_stream_response(conversation_id, &chunk)
            .await
            .map_err(|e| format!("Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {}", e))??;
        
        if let Some(content) = content {
            print!("{}", content);
            io::stdout().flush()?;
            buffer.push_str(&content);
        }
    }
    
    agent.add_message(conversation_id, "assistant", &buffer)
        .await
        .map_err(|e| format!("ÙØ´Ù„ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø³Ø§Ù„Ø©: {}", e))?;
    Ok(())
}
```

Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ØŒ ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù `Cargo.toml`:

```toml
[dependencies]
tokio = { version = "1.0", features = ["full"] }
serde_json = "1.0"
reqwest = { version = "0.11", features = ["stream"] }
tui = "0.19"
crossterm = "0.27"
env_logger = "0.10"
log = "0.4"
bytes = "1.0"
futures = "0.3"
```

Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„ØªÙŠ ØªÙ…Øª Ø¥Ø¶Ø§ÙØªÙ‡Ø§:

1. ÙˆØ§Ø¬Ù‡Ø© Ù…Ø³ØªØ®Ø¯Ù… ØªÙØ§Ø¹Ù„ÙŠØ© (TUI) Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `crossterm` Ùˆ `tui`
2. Ù…Ù‡Ù„Ø§Øª Ø²Ù…Ù†ÙŠØ© Ù„ÙƒÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø´Ø¨ÙƒÙŠØ©
3. ØªØ­Ø³ÙŠÙ†Ø§Øª ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙˆØ³Ø¹Ø© Ù…Ø¹ Ø±Ø³Ø§Ø¦Ù„ ÙˆØ§Ø¶Ø­Ø©
5. ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø­Ø¬Ù… Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰
6. Ø¥Ø¯Ø§Ø±Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª ÙˆØ§Ù„Ù…ÙˆØ§Ø±Ø¯
7. ÙØµÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚ Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª ÙØ±Ø¹ÙŠØ©
8. ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF
9. Ø¯Ø¹Ù… Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
10. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„ØªÙØµÙŠÙ„ÙŠ

Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
- Ø§Ø¶ØºØ· `s` Ù„Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆÙŠØ¨
- Ø§Ø¶ØºØ· `r` Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø¨Ø­Ø«ÙŠØ©
- Ø§Ø¶ØºØ· `q` Ù„Ù„Ø®Ø±ÙˆØ¬

ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙÙŠ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù…Ø«Ù„:
- `TIMEOUT_DURATION` Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ù‡Ù„Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©
- `MAX_FILE_SIZE` Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§
- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ

ÙŠØ¬Ø¨ ØªÙ†ÙÙŠØ° Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ø«Ù„ `agent`ØŒ `model`ØŒ Ø¥Ù„Ø®) ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¶Ø§ÙØ©.
"""

