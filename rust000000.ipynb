{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVZGwmdX7Cuc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQ7dlXWA8egp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlqQA_CC8eju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQgFq2aS8emt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GV2qsHcI8epu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use anyhow::{Context, Result};\n",
        "use lopdf;\n",
        "use regex::Regex;\n",
        "use std::collections::{HashMap, HashSet};\n",
        "use std::env;\n",
        "use std::io::{self, Write};\n",
        "use rust_stemmers::{Algorithm, Stemmer};\n",
        "\n",
        "// Ù‚Ø§Ø¦Ù…Ø© Ø¨ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
        "const ARABIC_STOP_WORDS: &[&str] = &[\n",
        "    \"Ùˆ\", \"ÙÙŠ\", \"Ù…Ù†\", \"Ø¥Ù„Ù‰\", \"Ø¹Ù„Ù‰\", \"Ø£Ù†\", \"Ù„Ø§\", \"Ù…Ø§\", \"Ù‡Ø°Ø§\", \"Ù‡Ø°Ù‡\", \"Ø°Ù„Ùƒ\", \"Ù‡Ø¤Ù„Ø§Ø¡\",\n",
        "    \"Ø¥Ø°Ø§\", \"Ø¥Ù†\", \"ÙƒØ§Ù†\", \"ÙŠÙƒÙˆÙ†\", \"Ø¹Ù†\", \"Ù…Ø¹\", \"Ù‡Ùˆ\", \"Ù‡ÙŠ\", \"Ù‡Ù…\", \"Ø¨\", \"Ùƒ\", \"Ù„\", \"ÙŠØ§\",\n",
        "];\n",
        "\n",
        "struct NLPProcessor {\n",
        "    stemmer: Stemmer,\n",
        "    stop_words: HashSet<String>,\n",
        "}\n",
        "\n",
        "impl NLPProcessor {\n",
        "    fn new() -> Self {\n",
        "        let mut stop_words = HashSet::new();\n",
        "        for word in ARABIC_STOP_WORDS {\n",
        "            stop_words.insert(word.to_string());\n",
        "        }\n",
        "\n",
        "        NLPProcessor {\n",
        "            stemmer: Stemmer::create(Algorithm::Arabic),\n",
        "            stop_words,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    fn process_text(&self, text: &str) -> Vec<String> {\n",
        "        text.split_whitespace()\n",
        "            .filter_map(|word| {\n",
        "                let cleaned = word.trim_matches(|c: char| !c.is_alphanumeric()).to_lowercase();\n",
        "                if !cleaned.is_empty() && !self.stop_words.contains(&cleaned) {\n",
        "                    Some(self.stemmer.stem(&cleaned).to_string())\n",
        "                } else {\n",
        "                    None\n",
        "                }\n",
        "            })\n",
        "            .collect()\n",
        "    }\n",
        "}\n",
        "\n",
        "fn extract_text_from_pdf(path: &str) -> Result<String> {\n",
        "    let doc = lopdf::Document::load(path).context(\"Failed to load PDF document\")?;\n",
        "\n",
        "    let mut text = String::new();\n",
        "    for page_number in 1..=doc.get_pages().len() {\n",
        "        if let Ok(page_text) = doc.extract_text(&[page_number]) {\n",
        "            text.push_str(&page_text);\n",
        "            text.push('\\n');\n",
        "        }\n",
        "    }\n",
        "\n",
        "    let re = Regex::new(r\"\\s+\").unwrap();\n",
        "    Ok(re.replace_all(&text, \" \").into_owned())\n",
        "}\n",
        "\n",
        "fn semantic_search(query: &str, corpus: &[&str], nlp: &NLPProcessor) -> Vec<(usize, f32)> {\n",
        "    let query_terms = nlp.process_text(query);\n",
        "\n",
        "    let mut tfidf_scores = HashMap::new();\n",
        "    for (doc_id, doc) in corpus.iter().enumerate() {\n",
        "        let doc_terms = nlp.process_text(doc);\n",
        "        let mut score = 0.0_f32;\n",
        "\n",
        "        for term in &query_terms {\n",
        "            let tf = doc_terms.iter().filter(|&t| t == term).count() as f32;\n",
        "            let idf = (corpus.len() as f32 / (1.0 + corpus.iter()\n",
        "                .filter(|&&d| nlp.process_text(d).contains(term))\n",
        "                .count() as f32).ln_1p();\n",
        "\n",
        "            score += tf * idf;\n",
        "        }\n",
        "\n",
        "        if score > 0.0 {\n",
        "            tfidf_scores.insert(doc_id, score);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    let mut results: Vec<_> = tfidf_scores.into_iter().collect();\n",
        "    results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());\n",
        "    results\n",
        "}\n",
        "\n",
        "fn chat_loop(pdf_text: &str) {\n",
        "    let nlp = NLPProcessor::new();\n",
        "    let corpus: Vec<&str> = pdf_text.split('\\n').collect();\n",
        "    let mut synonyms = HashMap::new();\n",
        "    synonyms.insert(\"Ø¨Ø±Ù†Ø§Ù…Ø¬\", vec![\"ØªØ·Ø¨ÙŠÙ‚\", \"Ø³ÙˆÙØª ÙˆÙŠØ±\"]);\n",
        "    synonyms.insert(\"Ù…Ù„Ù\", vec![\"ÙˆØ«ÙŠÙ‚Ø©\", \"Ù…Ø³ØªÙ†Ø¯\"]);\n",
        "\n",
        "    println!(\"Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ø¯Ø®Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ Ø£Ùˆ Ø§ÙƒØªØ¨ 'Ø®Ø±ÙˆØ¬' Ù„Ù„Ù…ØºØ§Ø¯Ø±Ø©.\");\n",
        "    println!(\"Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø¨Ø­Ø«:\");\n",
        "    println!(\"1. Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© (Ø§Ø¨Ø¯Ø£ Ø¨ /k)\");\n",
        "    println!(\"2. Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ (Ø§ÙØªØ±Ø§Ø¶ÙŠ)\");\n",
        "\n",
        "    loop {\n",
        "        print!(\"> \");\n",
        "        io::stdout().flush().unwrap();\n",
        "\n",
        "        let mut input = String::new();\n",
        "        io::stdin().read_line(&mut input).unwrap();\n",
        "        let input = input.trim();\n",
        "\n",
        "        if input == \"Ø®Ø±ÙˆØ¬\" {\n",
        "            println!(\"Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©!\");\n",
        "            break;\n",
        "        }\n",
        "\n",
        "        let (search_type, query) = if input.starts_with(\"/k \") {\n",
        "            (\"keyword\", input.trim_start_matches(\"/k \").trim())\n",
        "        } else {\n",
        "            (\"semantic\", input)\n",
        "        };\n",
        "\n",
        "        // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª\n",
        "        let expanded_query = synonyms.iter().fold(query.to_string(), |acc, (key, values)| {\n",
        "            acc.replace(key, &values.join(\"|\"))\n",
        "        });\n",
        "\n",
        "        match search_type {\n",
        "            \"keyword\" => {\n",
        "                let results: Vec<&str> = corpus\n",
        "                    .iter()\n",
        "                    .filter(|&&line| line.contains(query))\n",
        "                    .copied()\n",
        "                    .collect();\n",
        "\n",
        "                print_results(&results);\n",
        "            }\n",
        "            _ => {\n",
        "                let results = semantic_search(&expanded_query, &corpus, &nlp);\n",
        "                if !results.is_empty() {\n",
        "                    println!(\"Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙƒØ«Ø± ØµÙ„Ø©:\");\n",
        "                    for (i, (doc_id, score)) in results.iter().take(3).enumerate() {\n",
        "                        println!(\"{}. [Score: {:.2}] {}\", i + 1, score, corpus[*doc_id]);\n",
        "                    }\n",
        "                } else {\n",
        "                    println!(\"Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø°Ø§Øª ØµÙ„Ø©.\");\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn print_results(results: &[&str]) {\n",
        "    if !results.is_empty() {\n",
        "        println!(\"Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {}\", results.len());\n",
        "        for (i, result) in results.iter().take(5).enumerate() {\n",
        "            println!(\"{}. {}\", i + 1, result);\n",
        "        }\n",
        "    } else {\n",
        "        println!(\"Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬.\");\n",
        "    }\n",
        "}\n",
        "\n",
        "fn main() -> Result<()> {\n",
        "    let args: Vec<String> = env::args().collect();\n",
        "    if args.len() < 2 {\n",
        "        eprintln!(\"Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {} <Ù…Ù„Ù1.pdf> [Ù…Ù„Ù2.pdf ...]\", args[0]);\n",
        "        std::process::exit(1);\n",
        "    }\n",
        "\n",
        "    let mut combined_text = String::new();\n",
        "    for path in &args[1..] {\n",
        "        let text = extract_text_from_pdf(path)?;\n",
        "        combined_text.push_str(&text);\n",
        "        combined_text.push('\\n');\n",
        "    }\n",
        "\n",
        "    chat_loop(&combined_text);\n",
        "    Ok(())\n",
        "}"
      ],
      "metadata": {
        "id": "00pBIBXu8esG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-89ehi1h8jxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FueDF3kpwtE-",
        "outputId": "b5d440eb-26f7-4efa-ad0f-1abf111a010f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mprofile set to 'default'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[0m\u001b[1minfo: \u001b[0msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mlatest update on 2025-04-03, rust version 1.86.0 (05f9846f8 2025-03-31)\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'cargo'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'clippy'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rust-docs'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rust-std'\n",
            " 27.1 MiB /  27.1 MiB (100 %)  26.6 MiB/s in  1s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rustc'\n",
            " 72.8 MiB /  72.8 MiB (100 %)  33.1 MiB/s in  2s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdownloading component 'rustfmt'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'cargo'\n",
            "  8.8 MiB /   8.8 MiB (100 %)   7.4 MiB/s in  1s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'clippy'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rust-docs'\n",
            " 21.2 MiB /  21.2 MiB (100 %)   2.7 MiB/s in  8s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rust-std'\n",
            " 27.1 MiB /  27.1 MiB (100 %)   7.3 MiB/s in  4s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rustc'\n",
            " 72.8 MiB /  72.8 MiB (100 %)   8.4 MiB/s in  9s\n",
            "\u001b[0m\u001b[1minfo: \u001b[0minstalling component 'rustfmt'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[0m\u001b[1m\u001b[0m\u001b[1m\u001b[32mstable-x86_64-unknown-linux-gnu installed\u001b[0m - rustc 1.86.0 (05f9846f8 2025-03-31)\n",
            "\n",
            "\u001b[0m\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[0m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[0m\u001b[1mPATH\u001b[0m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, you need to source\n",
            "the corresponding \u001b[0m\u001b[1menv\u001b[0m file under $HOME/.cargo.\n",
            "\n",
            "This is usually done by running one of the following (note the leading DOT):\n",
            ". \"$HOME/.cargo/env\"            # For sh/bash/zsh/ash/dash/pdksh\n",
            "source \"$HOME/.cargo/env.fish\"  # For fish\n",
            "source $\"($nu.home-path)/.cargo/env.nu\"  # For nushell\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] += \":$HOME/.cargo/bin\""
      ],
      "metadata": {
        "id": "IPnwI-oGww2t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ØªØ«Ø¨ÙŠØª Rust\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "\n",
        "# ØªØ­Ø¯ÙŠØ« Ù…ØªØºÙŠØ± PATH Ù„Ø¬Ø¹Ù„Ù‡ Ù…ØªØ§Ø­Ù‹Ø§ Ù„Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù„Ø§Ø­Ù‚Ø©\n",
        "import os\n",
        "home_dir = os.path.expanduser(\"~\") # Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù€ $HOME\n",
        "cargo_bin_path = os.path.join(home_dir, \".cargo\", \"bin\")\n",
        "if cargo_bin_path not in os.environ['PATH']:\n",
        "    os.environ['PATH'] = f\"{cargo_bin_path}:{os.environ['PATH']}\"\n",
        "\n",
        "print(\"PATH updated.\")\n",
        "!echo $PATH # Ù„Ù„ØªØ­Ù‚Ù‚"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQrGrn2lwxL9",
        "outputId": "9acff756-ae28-4234-c1c2-bed1909e8fdb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mIt looks like you have an existing rustup settings file at:\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0m/root/.rustup/settings.toml\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mRustup will install the default toolchain as specified in the settings file,\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0minstead of the one inferred from the default host triple.\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mprofile set to 'default'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault host triple is x86_64-unknown-linux-gnu\n",
            "\u001b[0m\u001b[1m\u001b[33mwarn: \u001b[0mUpdating existing toolchain, profile choice will be ignored\n",
            "\u001b[0m\u001b[1minfo: \u001b[0msyncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "\u001b[0m\u001b[1minfo: \u001b[0mdefault toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "\n",
            "  \u001b[0m\u001b[1mstable-x86_64-unknown-linux-gnu unchanged\u001b[0m - rustc 1.86.0 (05f9846f8 2025-03-31)\n",
            "\n",
            "\u001b[0m\u001b[1m\n",
            "Rust is installed now. Great!\n",
            "\u001b[0m\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your \u001b[0m\u001b[1mPATH\u001b[0m environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, you need to source\n",
            "the corresponding \u001b[0m\u001b[1menv\u001b[0m file under $HOME/.cargo.\n",
            "\n",
            "This is usually done by running one of the following (note the leading DOT):\n",
            ". \"$HOME/.cargo/env\"            # For sh/bash/zsh/ash/dash/pdksh\n",
            "source \"$HOME/.cargo/env.fish\"  # For fish\n",
            "source $\"($nu.home-path)/.cargo/env.nu\"  # For nushell\n",
            "PATH updated.\n",
            "/root/.cargo/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:$HOME/.cargo/bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which cargo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVRw98A6w0C1",
        "outputId": "a1de7147-6739-4305-9d82-7607ddbd76d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cargo/bin/cargo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cargo --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wp7ql-6w5Rl",
        "outputId": "531c1d48-9c62-4a83-f974-b4400d4fd5a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cargo 1.86.0 (adf9b6ad1 2025-02-28)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!rustc --version\n",
        "!cargo --version"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVY_rmj_w9pw",
        "outputId": "fa3e6a5d-0b33-4147-c85c-9026f3f27956"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rustc 1.86.0 (05f9846f8 2025-03-31)\n",
            "cargo 1.86.0 (adf9b6ad1 2025-02-28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y cmake libfontconfig1-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCY9u0NP8l69",
        "outputId": "567441ba-ffaf-4911-c0fd-45be96f7c942"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libfontconfig1-dev is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libfontconfig1-dev set to manually installed.\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ø¥Ù„ÙŠÙƒ Ø¯Ù„ÙŠÙ„ ØªÙØµÙŠÙ„ÙŠ Ù„Ø¨Ø¯Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ø¨Ù„ØºØ© Rust Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©:\n",
        "\n",
        "1. ØªØ«Ø¨ÙŠØª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©\n",
        "bash\n",
        "# ØªØ«Ø¨ÙŠØª Rust (Ù„ÙŠÙ†ÙƒØ³/Ù…Ø§Ùƒ)\n",
        "curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n",
        "\n",
        "# Ù„Ù„ØªØ­Ø¯ÙŠØ« Ù„Ø¢Ø®Ø± Ù†Ø³Ø®Ø©\n",
        "rustup update\n",
        "2. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø¯ÙŠØ¯\n",
        "bash\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ø«Ù†Ø§Ø¦ÙŠ (Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ´ØºÙŠÙ„)\n",
        "cargo new my_project --bin\n",
        "\n",
        "# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø´Ø±ÙˆØ¹ Ù…ÙƒØªØ¨Ø©\n",
        "cargo new my_lib --lib\n",
        "3. Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ\n",
        "my_project/\n",
        "â”œâ”€â”€ Cargo.toml    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø¹ÙŠØ§Øª\n",
        "â”œâ”€â”€ src/\n",
        "â”‚   â””â”€â”€ main.rs   # Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n",
        "â””â”€â”€ tests/        # Ù…Ù„ÙØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)\n",
        "4. Ù…Ù„Ù Cargo.toml Ù†Ù…ÙˆØ°Ø¬ÙŠ\n",
        "toml\n",
        "[package]\n",
        "name = \"my_project\"\n",
        "version = \"0.1.0\"\n",
        "edition = \"2021\"\n",
        "\n",
        "[dependencies]\n",
        "serde = \"1.0\"    # Ù…Ø«Ø§Ù„ Ù„Ø¥Ø¶Ø§ÙØ© ØªØ¨Ø¹ÙŠØ©\n",
        "5. Ù…Ø«Ø§Ù„ Ù„Ù…Ù„Ù main.rs Ø¨Ø³ÙŠØ·\n",
        "rust\n",
        "fn main() {\n",
        "    println!(\"Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…! ğŸ¦€\");\n",
        "\n",
        "    let numbers = vec![1, 2, 3, 4, 5];\n",
        "    let sum: i32 = numbers.iter().sum();\n",
        "\n",
        "    println!(\"Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…: {}\", sum);\n",
        "\n",
        "    let result = divide(10, 2);\n",
        "    match result {\n",
        "        Ok(val) => println!(\"Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø³Ù…Ø©: {}\", val),\n",
        "        Err(e) => println!(\"Ø®Ø·Ø£: {}\", e),\n",
        "    }\n",
        "}\n",
        "\n",
        "fn divide(a: i32, b: i32) -> Result<f64, String> {\n",
        "    if b == 0 {\n",
        "        Err(\"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±\".to_string())\n",
        "    } else {\n",
        "        Ok(a as f64 / b as f64)\n",
        "    }\n",
        "}\n",
        "6. Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
        "bash\n",
        "# ØªØ¬Ù…ÙŠØ¹ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹\n",
        "cargo run\n",
        "\n",
        "# ØªØ¬Ù…ÙŠØ¹ Ù„Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ\n",
        "cargo build --release\n",
        "\n",
        "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª\n",
        "cargo test\n",
        "\n",
        "# ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª\n",
        "cargo update\n",
        "\n",
        "# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚\n",
        "cargo doc --open\n",
        "7. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©\n",
        "Ø£. Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ù .rustfmt.toml Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒÙˆØ¯"
      ],
      "metadata": {
        "id": "Cz8kqjuH9s2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cargo new my_project --bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VxY5o1o97QW",
        "outputId": "52ea14cd-214f-4f0b-b620-69701a22e4da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[32m    Creating\u001b[0m binary (application) `my_project` package\n",
            "\u001b[1m\u001b[36mnote\u001b[0m\u001b[1m:\u001b[0m see more `Cargo.toml` keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/my_project\n",
        "!cargo run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rox0FlA973G",
        "outputId": "d5ef52a5-016f-4735-bce1-ccddd1f500b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/my_project\n",
            "\u001b[1m\u001b[31merror\u001b[0m\u001b[1m:\u001b[0m failed to parse manifest at `/content/my_project/Cargo.toml`\n",
            "\n",
            "Caused by:\n",
            "  no targets specified in the manifest\n",
            "  either src/lib.rs, src/main.rs, a [lib] section, or [[bin]] section must be present\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hh4d7YDn-UaO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}